# -*- coding: utf-8 -*-
"""Group 8 Machine learning Assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18YEqf-coNeP721YTjcpqt9DSHEmu4gHJ

# **Problem 1: Import the data and |split the data and train Logistic regression and KNN models**
"""

# Commented out IPython magic to ensure Python compatibility.
#import important libraries
import numpy as np #to deal with arrays
import pandas as pd #to deal with dataframes
import matplotlib.pyplot as plt #pyplot is a collection of command style functions that make matplotlib work like MATLAB
import seaborn as sns #for visualization
from sklearn.datasets import load_wine #load the dataset
from sklearn.model_selection import train_test_split #for test and train split
from sklearn.metrics import confusion_matrix,accuracy_score
from sklearn import metrics
from sklearn.metrics import classification_report, plot_confusion_matrix #to use the function of classification report and confuion matrix
# %matplotlib inline

#read the dataset
df = pd.read_csv('/content/Assignment3_dataset.csv')
df.head()

#get some informations about the data
df.info()

#describe the dataset
df.describe()

#split the data into train and test split
X = df.drop('Outcome',axis=1)
y = df['Outcome']

from sklearn.model_selection import train_test_split
x_train , x_test ,y_train ,y_test = train_test_split(X,y,test_size = 0.25 ,random_state=0, shuffle=False)

x_train

print(len(x_train))

print(len(y_test))

"""## **Apply Logistic regression model**

Logistic regression estimates the probability of an event occurring, such as voted or didn't vote, based on a given dataset of independent variables. Since the outcome is a probability, the dependent variable is bounded between 0 and 1.
"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(x_train,y_train)
y_pred_lr = lr.predict(x_test)

#print accuracy and classification report of LR 
from sklearn.metrics import classification_report ,accuracy_score
lr_accuracy =accuracy_score(y_test,y_pred_lr)
print(lr_accuracy)
print(classification_report(y_train,lr.predict(x_train)))
print(classification_report(y_test,y_pred_lr))

#confusion matrix for logistic regression model
cm = metrics.confusion_matrix(y_test, y_pred_lr)
print(cm)

score = lr.score(x_test, y_test)
print(score)

plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt=".3f", linewidths=.5, square = True, cmap = 'Blues_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Accuracy Score: {0}'.format(score)
plt.title(all_sample_title, size = 15);

"""## **Apply KNN model**

K Nearest Neighbor algorithm falls under the Supervised Learning category and is used for classification (most commonly) and regression. It is a versatile algorithm also used for imputing missing values and resampling datasets. As the name (K Nearest Neighbor) suggests it considers K Nearest Neighbors (Data points) to predict the class or continuous value for the new Datapoint.
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(x_train,y_train)
y_pred_knn = knn.predict(x_test)

#print accuracy and classification report of  KNN
knn_accracy=accuracy_score(y_test,y_pred_knn)
print(knn_accracy)
print(classification_report(y_train,knn.predict(x_train)))
print(classification_report(y_test,y_pred_knn))

cm = confusion_matrix(y_test, y_pred_knn)
ac = accuracy_score(y_test,y_pred_knn)

#print the accuracy score for knn model
score_knn = knn.score(x_test, y_test)
print(score_knn)

plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt=".3f", linewidths=.5, square = True, cmap = 'Blues_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Accuracy Score: {0}'.format(score_knn)
plt.title(all_sample_title, size = 15);

"""## **Apply TSNE for plotting on training and testing**

T-distributed Stochastic Neighbor Embedding: is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.
"""

from sklearn.manifold import TSNE

"""### **Apply TSNE on training set**"""

tsne = TSNE(n_components=2,random_state=0)
z = tsne.fit_transform(x_train)

df1 = pd.DataFrame()
df1["y_knn"] = knn.predict(x_train)
df1["y_lr"] = lr.predict(x_train)
df1["y_actual"] = y_train
df1["comp-1"] = z[:,0]
df1["comp-2"] = z[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df1.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df1).set(title="TSNE on training with actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df1.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df1).set(title="TSNE on training with predicted Logistic regression labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df1.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df1).set(title="TSNE on training with predicted knn label")

"""### **Apply TSNE on testing set**"""

tsne2 = TSNE(n_components=2,random_state=0)
z2 = tsne2.fit_transform(x_test)

df2 = pd.DataFrame()
df2["y_knn"] =y_pred_knn
df2["y_lr"] = y_pred_lr
df2["y_actual"] = y_test
df2["comp-1"] = z2[:,0]
df2["comp-2"] = z2[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df2.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df2).set(title="TSNE on testing with actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df2.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df2).set(title="TSNE on testing with predicted Logistic regression labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df2.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df2).set(title="TSNE on testing with predicted knn labels")

"""# **Question 2: Choose the best number of cluster for k-means clustering algorithm**"""

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
wcss=[]
scores =[]
for i in range(2,20):
  kmean = KMeans(n_clusters=i)
  kmean.fit(X)
  wcss.append(kmean.inertia_)
  y_pred= kmean.predict(X)
  scores.append(silhouette_score(X,y_pred))
plt.xlabel('K value')
plt.ylabel('WCSS')
sns.lineplot(x=range(2,20),y=wcss,).set(title="K value Vs WCSS")

from yellowbrick.cluster import KElbowVisualizer
visualizer = KElbowVisualizer(kmean, k=(2,20))
visualizer.fit(X)       
visualizer.show()

plt.xlabel('K value')
plt.ylabel('silhouette_score')
sns.lineplot(x=range(2,20),y=scores,).set(title="K value Vs silhouette_score")

"""**As we can see, the optimal number of k based on the silhouette score is k = 2**"""

kmean = KMeans(n_clusters=2)
y_cluster = kmean.fit_predict(X)

tsne3 = TSNE(n_components=2,random_state=0)
z3 = tsne3.fit_transform(X)

df3 = pd.DataFrame()
df3["y_Kmean"] = y_cluster
df3["comp-1"] = z3[:,0]
df3["comp-2"] = z3[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df3.y_Kmean.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df3).set(title="TSNE on Kmean with Cluster labels")

"""# **Question 3: Apply PCA**

Principal component analysis, or PCA, is a statistical procedure that allows you to summarize the information content in large data tables by means of a smaller set of “summary indices” that can be more easily visualized and analyzed.
"""

#apply pca on the data
from sklearn.decomposition import PCA
scores_lr = []
scores_knn = []
for i in range(2,8):
  pca= PCA(n_components=i)
  x_train_pca = pca.fit_transform(x_train)
  x_test_pca = pca.transform(x_test)
  lr = LogisticRegression()
  lr.fit(x_train_pca,y_train)
  y_pred_lr = lr.predict(x_test_pca)
  scores_lr.append(accuracy_score(y_pred_lr,y_test))
  knn = KNeighborsClassifier()
  knn.fit(x_train_pca,y_train)
  y_pred_knn = knn.predict(x_test_pca)
  scores_knn.append(accuracy_score(y_pred_knn,y_test))

#scores of logistic regression model with PCA
scores_lr

#scores of knn model with PCA
scores_knn

# n =7 is the best number number of coponebt that achieve high accuarcy on lr and knn
for i,j,k in zip(range(2,8),scores_lr,scores_knn):
  print((i,j,k))

plt.title('number of feature with PCA and the accuracy for LR with baseline')
plt.xlabel('number of feature')
plt.ylabel('Accuracy score')
plt.plot(range(2,8),[lr_accuracy,lr_accuracy,lr_accuracy,lr_accuracy,lr_accuracy,lr_accuracy])
plt.plot(range(2,8),scores_lr)
plt.legend(labels=['baseline : blue','accuracies : Green'])

plt.title('number of feature with PCA and the accuracy for LR with baseline')
plt.xlabel('number of feature')
plt.ylabel('Accuracy score')
plt.bar(range(2,8),[lr_accuracy,lr_accuracy,lr_accuracy,lr_accuracy,lr_accuracy,lr_accuracy])
plt.bar(range(2,8),scores_lr)
plt.legend(labels=['baseline : blue','accuracies : Green'],loc='lower left')

plt.title('number of feature with PCA and the accuracy for KNN with baseline')
plt.xlabel('number of feature')
plt.ylabel('Accuracy score')
plt.plot(range(2,8),[knn_accracy,knn_accracy,knn_accracy,knn_accracy,knn_accracy,knn_accracy])
plt.plot(range(2,8),scores_knn)
plt.legend(labels=['baseline : blue','accuracies : Green'])

plt.title('number of feature with PCA and the accuracy for KNN with baseline')
plt.xlabel('number of feature')
plt.ylabel('Accuracy score')
plt.bar(range(2,8),[knn_accracy,knn_accracy,knn_accracy,knn_accracy,knn_accracy,knn_accracy])
plt.bar(range(2,8),scores_knn)
plt.legend(labels=['baseline : blue','accuracies : Green'],loc='lower left')

"""## **Apply PCA on the best number of n**"""

pca= PCA(n_components=7)
x_train_pca = pca.fit_transform(x_train)
x_test_pca = pca.transform(x_test)
lr = LogisticRegression()
lr.fit(x_train_pca,y_train)
y_pred_lr = lr.predict(x_test_pca)

knn = KNeighborsClassifier()
knn.fit(x_train_pca,y_train)
y_pred_knn = knn.predict(x_test_pca)

print('accuracy for lr with PCA : ',accuracy_score(y_test,y_pred_lr))
print('accuracy for knn with PCA : ',accuracy_score(y_test,y_pred_knn))

"""## **Apply TSNE on training data**"""

tsne4 = TSNE(n_components=2,random_state=0)
z4 = tsne4.fit_transform(x_train_pca)

df4 = pd.DataFrame()
df4["y_lr"] = lr.predict(x_train_pca)
df4["y_knn"] =knn.predict(x_train_pca)
df4["y_actual"] = y_train
df4["comp-1"] = z4[:,0]
df4["comp-2"] = z4[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df4.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df4).set(title="TSNE on training data with pca actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df4.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df4).set(title="TSNE on training data with pca knn predicted labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df4.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df4).set(title="TSNE on training data with pca lr predicted labels")

"""## **Apply TSNE on testing data**"""

tsne5 = TSNE(n_components=2,random_state=0)
z5 = tsne5.fit_transform(x_test_pca)

df5 = pd.DataFrame()
df5["y_lr"] = y_pred_lr
df5["y_knn"] =y_pred_knn
df5["y_actual"] = y_test
df5["comp-1"] = z5[:,0]
df5["comp-2"] = z5[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df5.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df5).set(title="TSNE on test data with pca actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df5.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df5).set(title="TSNE on test data with pca lr predicted label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df5.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df5).set(title="TSNE on test data with pca knn predicted label")

"""# **Question 4: Apply Feature Selection methods**

## **Apply filter methods** : Filter methods pick up the intrinsic properties of the features measured via univariate statistics instead of cross-validation performance. These methods are faster and less computationally expensive than wrapper methods. When dealing with high-dimensional data, it is computationally cheaper to use filter methods.

### **Information gain method**

Information gain calculates the reduction in entropy from the transformation of a dataset. It can be used for feature selection by evaluating the Information gain of each variable in the context of the target variable.
"""

X

# information Gain
from traitlets.traitlets import ForwardDeclaredInstance
from sklearn.feature_selection import mutual_info_classif
importance = mutual_info_classif(X,y)
feat_importance = pd.Series(importance,df.columns[0:len(df.columns)-1])
feat_importance.plot(kind='barh')

# based on information gain we will select the highest four feature that has information gain
x_train_ig = x_train[['Age','BMI','Glucose','Pregnancies']]
x_test_ig = x_test[['Age','BMI','Glucose','Pregnancies']]

#Apply LR on the information gain
lr_ig = LogisticRegression()
lr_ig.fit(x_train_ig,y_train)
y_pred_ig_lr = lr_ig.predict(x_test_ig)

lr_ig_accracy=accuracy_score(y_test,y_pred_ig_lr)
print(lr_ig_accracy)
print(classification_report(y_train,lr_ig.predict(x_train_ig)))
print(classification_report(y_test,y_pred_ig_lr))

#feature selection method to compare between the features
def featureSelection(x_train, y_train, x_test, y_test, FSM, model):
  fs = FSM
  fs.fit(x_train, y_train.values.ravel())
  X_train_new = fs.transform(x_train)
  X_test_new = fs.transform(x_test) 
  model.fit(X_train_new, y_train.values.ravel())
  y_pred = model.predict(X_test_new)
  accuracyScore = accuracy_score(y_test, y_pred) * 100
  
  return accuracyScore

from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.feature_selection import mutual_info_classif
def FilterMethod(x_train1, y_train1, x_test1, y_test1,  model_name):
  accuracy_dic={}
  accuracy_list=[]
  accuracy_list2=[]
  model = model_name
  for i in range(2,9):
    fsm =  SelectKBest(mutual_info_classif, k=i)
    accuracyScore = featureSelection(x_train1, y_train1, x_test1, y_test1, fsm, model)
    accuracy_list.append(accuracyScore)
    fsm2 =  SelectKBest(f_classif, k=i) 
    acc2 = featureSelection(x_train1, y_train1, x_test1, y_test1, fsm2, model)
    accuracy_list2.append(acc2)
  print(accuracy_list)
  print('max mutal',max(accuracy_list))
  print(accuracy_list2)
  print('max anova',max(accuracy_list2))
  if(max(accuracy_list)>max(accuracy_list2)):
    best_n=accuracy_list.index(max(accuracy_list))+2
    print("Best value of n components: ",best_n, "from Mutual information for a discrete target filter method")
    accuracy_dic={"n-component":[2,3,4,5,6,7,8],"accuracy":accuracy_list}
    accuracy_df=pd.DataFrame(accuracy_dic)
    ax=sns.barplot(x="n-component", y='accuracy', data=accuracy_df,
                palette=["b" if x!=8 else 'g' for x in accuracy_df['n-component']]).set(title=' Mutual information for a discrete target filter method')
  else:
    best_n=  accuracy_list2.index(max(accuracy_list2))+2
    print("Best value of n components : ",best_n, 'from ANOVA')
    #accuracy_list.append(accuracy_score(y_test, y_pred_LR))
    accuracy_dic={"n-component":[2,3,4,5,6,7,8],"accuracy":accuracy_list2}
    accuracy_df=pd.DataFrame(accuracy_dic)
    ax=sns.barplot(x="n-component", y='accuracy', data=accuracy_df,
                palette=["b" if x!=8 else 'g' for x in accuracy_df['n-component']]).set(title='ANOVA filter method')

FilterMethod(x_train, y_train, x_test, y_test, LogisticRegression())

#Apply KNN with information gain
knn_ig = KNeighborsClassifier()
knn_ig.fit(x_train_ig,y_train)
y_pred_ig_knn = knn_ig.predict(x_test_ig)

knn_ig_accracy=accuracy_score(y_test,y_pred_ig_knn)
print(knn_ig_accracy)
print(classification_report(y_train,knn_ig.predict(x_train_ig)))
print(classification_report(y_test,y_pred_ig_knn))

FilterMethod(x_train, y_train, x_test, y_test, KNeighborsClassifier())

"""#### **Apply TSNE on training data with information gain**"""

tsne6 = TSNE(n_components=2,random_state=0)
z6 = tsne6.fit_transform(x_train_ig)

df6 = pd.DataFrame()
df6["y_lr"] = lr_ig.predict(x_train_ig)
df6["y_knn"] =knn_ig.predict(x_train_ig)
df6["y_actual"] = y_train
df6["comp-1"] = z6[:,0]
df6["comp-2"] = z6[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df6.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df6).set(title="TSNE on train with information gain filter data actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df6.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df6).set(title="TSNE on train with information gain filter data lr predicted labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df6.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df6).set(title="TSNE on train with information gain filter data knn predicted labels")

"""#### **Apply TSNE on testing data with information gain**"""

tsne7 = TSNE(n_components=2,random_state=0)
z7 = tsne7.fit_transform(x_test_ig)

df7 = pd.DataFrame()
df7["y_lr"] = y_pred_ig_lr
df7["y_knn"] = y_pred_ig_knn
df7["y_actual"] = y_test
df7["comp-1"] = z7[:,0]
df7["comp-2"] = z7[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df7.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df7).set(title="TSNE on test with information gain filter data actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df7.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df7).set(title="TSNE on test with information gain filter data predicted lr labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df7.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df7).set(title="TSNE on test with information gain filter data predicted knn labels")

"""## **Apply Variance threshold**

The variance threshold is a simple baseline approach to feature selection. It removes all features which variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples. We assume that features with a higher variance may contain more useful information, but note that we are not taking the relationship between feature variables or feature and target variables into account, which is one of the drawbacks of filter methods.
"""

# Variance threshold 
from sklearn.feature_selection import VarianceThreshold
v = VarianceThreshold(threshold=0.02)
v.fit(X)
v.get_support()

X.columns

#select the train and test features for variance threshold
x_train_v = x_train[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','Age']]
x_test_v = x_test[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','Age']]

#apply LR model with variance threshold
lr_v = LogisticRegression()
lr_v.fit(x_train_v,y_train)
y_pred_v_lr = lr_v.predict(x_test_v)

lr_v_accracy=accuracy_score(y_test,y_pred_v_lr)
print(lr_v_accracy)
print(classification_report(y_train,lr_v.predict(x_train_v)))
print(classification_report(y_test,y_pred_v_lr))

#apply knn model with variance threshold
knn_v = KNeighborsClassifier()
knn_v.fit(x_train_v,y_train)
y_pred_v_knn = knn_v.predict(x_test_v)

knn_v_accracy=accuracy_score(y_test,y_pred_v_knn)
print(knn_v_accracy)
print(classification_report(y_train,knn_v.predict(x_train_v)))
print(classification_report(y_test,y_pred_v_knn))

#feature selection method to compare between the features
def varianceThresholdFunc(x_train_v, y_train, x_test_v, y_test, FSM, model):
  vt = FSM
  vt.fit(x_train_v, y_train.values.ravel())
  X_train_new = vt.transform(x_train_v)
  X_test_new = vt.transform(x_test_v) 
  model.fit(X_train_new, y_train.values.ravel())
  y_pred = model.predict(X_test_new)
  accuracyScore = accuracy_score(y_test, y_pred) * 100
  return accuracyScore

def vtmethod(x_train1, y_train1, x_test1, y_test1,  model_name):
  accuracy_dic={}
  accuracy_list=[]
  accuracy_list2=[]
  model = model_name
  for i in range(2,9):
    fsm =  SelectKBest(mutual_info_classif, k=i)
    accuracyScore = featureSelection(x_train1, y_train1, x_test1, y_test1, fsm, model)
    accuracy_list.append(accuracyScore)
    fsm2 =  SelectKBest(f_classif, k=i) 
    acc2 = featureSelection(x_train1, y_train1, x_test1, y_test1, fsm2, model)
    accuracy_list2.append(acc2)
  print(accuracy_list)
  print('max mutal',max(accuracy_list))
  print(accuracy_list2)
  print('max anova',max(accuracy_list2))
  if(max(accuracy_list)>max(accuracy_list2)):
    best_n=accuracy_list.index(max(accuracy_list))+2
    print("Best value of n components: ",best_n, "Variance Threshold method")
    accuracy_dic={"n-component":[2,3,4,5,6,7,8],"accuracy":accuracy_list}
    accuracy_df=pd.DataFrame(accuracy_dic)
    ax=sns.barplot(x="n-component", y='accuracy', data=accuracy_df,
                palette=["b" if x!=8 else 'g' for x in accuracy_df['n-component']]).set(title=' Variance Threshold method')
  else:
    best_n=  accuracy_list2.index(max(accuracy_list2))+2
    print("Best value of n components : ",best_n, 'from ANOVA')
    accuracy_dic={"n-component":[2,3,4,5,6,7,8],"accuracy":accuracy_list2}
    accuracy_df=pd.DataFrame(accuracy_dic)
    ax=sns.barplot(x="n-component", y='accuracy', data=accuracy_df,
                palette=["b" if x!=8 else 'g' for x in accuracy_df['n-component']]).set(title='Variance Threshold method')

vtmethod(x_train, y_train, x_test, y_test, LogisticRegression())

vtmethod(x_train, y_train, x_test, y_test, KNeighborsClassifier())

"""#### **Apply TSNE on training set**"""

tsne8 = TSNE(n_components=2,random_state=0)
z8 = tsne8.fit_transform(x_train_v)

df8 = pd.DataFrame()
df8["y_lr"] = lr_v.predict(x_train_v)
df8["y_knn"] =knn_v.predict(x_train_v)
df8["y_actual"] = y_train
df8["comp-1"] = z8[:,0]
df8["comp-2"] = z8[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df8.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df8).set(title="tsne on train with variancethreshold filter data actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df8.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df8).set(title="tsne on train with variancethreshold filter data preictrd lr label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df8.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df8).set(title="tsne on train with variancethreshold filter data predicted knn label")

"""#### **Apply TSNE on testing set**"""

tsne9 = TSNE(n_components=2,random_state=0)
z9 = tsne9.fit_transform(x_test_v)

df9 = pd.DataFrame()
df9["y_lr"] = y_pred_v_lr
df9["y_knn"] =y_pred_v_knn
df9["y_actual"] = y_test
df9["comp-1"] = z9[:,0]
df9["comp-2"] = z9[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df9.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df9).set(title="tsne on test with variancethreshold filter data actual label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df9.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df9).set(title="tsne on test with variancethreshold filter data predicted lr label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df9.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df9).set(title="tsne on test with variancethreshold filter data predicted knn label")

"""## **wrapper method Backword feature selection**

Wrappers require some method to search the space of all possible subsets of features, assessing their quality by learning and evaluating a classifier with that feature subset. The feature selection process is based on a specific machine learning algorithm that we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion. The wrapper methods usually result in better predictive accuracy than filter methods.
"""

import joblib
import sys
sys.modules['sklearn.externals.joblib'] = joblib

! pip uninstall mlxtend --yes
! pip install mlxtend

from mlxtend.feature_selection import SequentialFeatureSelector as SFS
def wrapper_select_feature(X_train, y_train, X_test, y_test, label, model,i):
  fs = SFS(model,
           k_features=i,
           forward=label,
           verbose=2,
           scoring='roc_auc',
           cv=4)
  fs.fit(np.array(X_train), y_train.values.ravel())
  filtered_features= X_train.columns[list(fs.k_feature_idx_)]
  l=list(filtered_features)
  X_train_new = X_train.loc[:,l]
  X_test_new = X_test.loc[:,l]
  model.fit(X_train_new, y_train.values.ravel())
  y_pred = model.predict(X_test_new)
  acc = accuracy_score(y_test, y_pred) * 100
  
  return acc,X_train_new,X_test_new

def wsMethod(x_train1, y_train1, x_test1, y_test1,  model_name):
  accuracy_dic={}
  accuracy_list=[]
  accuracy_list2=[]
  feat=[]
  feat2=[]
  feat_test=[]
  feat_test2=[]
  model = model_name
  for i in range(2,9):
    acc,df_X_train_new,df_X_test_new = wrapper_select_feature(x_train1, y_train1, x_test1, y_test1,True , model_name,i)
    accuracy_list.append(acc)
    feat.append(df_X_train_new)
    feat_test.append(df_X_test_new)
    index=accuracy_list.index(max(accuracy_list))
    feat_name=feat[index]
    test_name=feat_test[index]

    acc2,df_X_train_new2,df_X_test_new2 = wrapper_select_feature(x_train1, y_train1, x_test1, y_test1,False , model_name,i)
    accuracy_list2.append(acc2)
    feat2.append(df_X_train_new2)
    feat_test2.append(df_X_test_new2)
    index2=accuracy_list2.index(max(accuracy_list2))
    feat_name2=feat2[index2]
    test_name2=feat_test2[index2]
  print(accuracy_list)
  print('max forward',max(accuracy_list))
  #print('list: ',feat_name)
  print(accuracy_list2)
  print('max backward',max(accuracy_list2))
  #print('list: ',feat_name2)

  if(max(accuracy_list)>max(accuracy_list2)):
    best_n=accuracy_list.index(max(accuracy_list))+2
    print("Best value of n components: ",best_n, "forward wrapper method")
    #accuracy_list.append(accuracy_score(y_test, y_pred_LR))
    accuracy_dic={"n-component":[2,3,4,5,6,7,8],"accuracy":accuracy_list}
    accuracy_df=pd.DataFrame(accuracy_dic)
    ax=sns.barplot(x="n-component", y='accuracy', data=accuracy_df,palette=["b" if x!=8 else 'g' for x in accuracy_df['n-component']]).set(title='feature selection using forward wrapper method')
    return feat_name,test_name
  else:
    best_n=  accuracy_list2.index(max(accuracy_list2))+2
    print("Best value of n components : ",best_n, 'backward wrapper method')
    #accuracy_list.append(accuracy_score(y_test, y_pred_LR))
    accuracy_dic={"n-component":[2,3,4,5,6,7,8],"accuracy":accuracy_list2}
    accuracy_df=pd.DataFrame(accuracy_dic)
    ax=sns.barplot(x="n-component", y='accuracy', data=accuracy_df, palette=["b" if x!=8 else 'g' for x in accuracy_df['n-component']]).set(title='feature selection using backward wrapper method')
    return feat_name2,test_name2

wsMethod(x_train, y_train, x_test, y_test, LogisticRegression())

from mlxtend.feature_selection import SequentialFeatureSelector
lr_be =LogisticRegression(class_weight='balanced',solver='lbfgs',n_jobs=-1,random_state=0,max_iter=500)
lr_be.fit(x_train,y_train)
b = SequentialFeatureSelector(lr_be,k_features='best',forward=False,n_jobs=-1)
b.fit(x_train,y_train)
feature = list(b.k_feature_names_)
x_train_b_lr = x_train[feature]
x_test_b_lr = x_test[feature]
lr_be.fit(x_train_b_lr,y_train)
y_pred_b_lr=lr_be.predict(x_test_b_lr)

lr_b_accracy=accuracy_score(y_test,y_pred_b_lr)
print(lr_b_accracy)
print(classification_report(y_train,lr_be.predict(x_train_b_lr)))
print(classification_report(y_test,y_pred_b_lr))

knn_be =KNeighborsClassifier()
knn_be.fit(x_train,y_train)
b = SequentialFeatureSelector(knn_be,k_features='best',forward=False)
b.fit(x_train,y_train)
feature = list(b.k_feature_names_)
x_train_b_knn = x_train[feature]
x_test_b_knn = x_test[feature]
knn_be.fit(x_train_b_knn,y_train)
y_pred_b_knn=knn_be.predict(x_test_b_knn)

feature

knn_b_accracy=accuracy_score(y_test,y_pred_b_lr)
print(knn_b_accracy)
print(classification_report(y_train,knn_be.predict(x_train_b_knn)))
print(classification_report(y_test,y_pred_b_knn))

wsMethod(x_train, y_train, x_test, y_test, KNeighborsClassifier())

"""### **Apply TSNE on training set**"""

tsne10 = TSNE(n_components=2,random_state=0)
z10 = tsne10.fit_transform(x_train_b_knn)

df10 = pd.DataFrame()
df10["y_lr"] = lr_be.predict(x_train_b_lr)
df10["y_knn"] =knn_be.predict(x_train_b_knn)
df10["y_actual"] = y_train
df10["comp-1"] = z10[:,0]
df10["comp-2"] = z10[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df10.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df10).set(title="TSNE on train with wraper BE filter data actual labels")

sns.scatterplot(x="comp-1", y="comp-2", hue=df10.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df10).set(title="TSNE on train with wraper BE filter data predicted lr label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df10.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df10).set(title="TSNE on train with wraper BE filter data predicted knn label")

"""### **Apply TSNE on tseting set**"""

tsne11 = TSNE(n_components=2,random_state=0)
z11 = tsne11.fit_transform(x_test_b_knn)

df11 = pd.DataFrame()
df11["y_lr"] = y_pred_b_lr
df11["y_knn"] =y_pred_b_knn
df11["y_actual"] = y_test
df11["comp-1"] = z11[:,0]
df11["comp-2"] = z11[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df11.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df11).set(title="TSNE on test with wraper BE filter data actual label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df11.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df11).set(title="TSNE on test with wraper BE filter data predicted lr label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df11.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df11).set(title="TSNE on test with wraper BE filter data predicted knn label")

"""## **Recursive feature elimination**

The goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute.
"""

# RFE
from sklearn.feature_selection import RFE
lr_r = LogisticRegression()
rfe =RFE(lr_r,n_features_to_select=4)
rfe.fit(x_train,y_train)
feature_r =list(rfe.feature_names_in_)
x_train_r = x_train[feature_r]
x_test_r = x_test[feature_r]
lr_r.fit(x_train_r,y_train)
y_pred_lr_r = rfe.predict(x_test_r)

lr_r_accracy=accuracy_score(y_test,y_pred_lr_r)
print(lr_r_accracy)
print(classification_report(y_train,lr_r.predict(x_train_r)))
print(classification_report(y_test,y_pred_lr_r))

# can`t apply RFE with KNN because doesn`t have a feature importance attribuite
from sklearn.tree import DecisionTreeClassifier
knn_r = DecisionTreeClassifier()
rfe_knn =RFE(knn_r,n_features_to_select=4)
rfe_knn.fit_transform(x_train,y_train)
feature_r =list(rfe_knn.feature_names_in_)
x_train_r_knn = x_train[feature_r]
x_test_r_knn = x_test[feature_r]
knn_r.fit(x_train_r_knn,y_train)
y_pred_knn_r = rfe_knn.predict(x_test_r_knn)

knn_r_accracy=accuracy_score(y_test,y_pred_knn_r)
print(knn_r_accracy)
print(classification_report(y_train,knn_r.predict(x_train_r_knn)))
print(classification_report(y_test,y_pred_knn_r))

"""### **TSNE on training data**"""

tsne12 = TSNE(n_components=2,random_state=0)
z12 = tsne12.fit_transform(x_train_r_knn)

df12 = pd.DataFrame()
df12["y_lr"] = lr_r.predict(x_train_r)
df12["y_knn"] =knn_r.predict(x_train_r_knn)
df12["y_actual"] = y_train
df12["comp-1"] = z12[:,0]
df12["comp-2"] = z12[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df12.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df12).set(title="tsne on train with wraper RE filter data actual label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df12.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df12).set(title="tsne on train with wraper RE filter data predicted lr label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df12.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df12).set(title="tsne on train with wraper RE filter data predicted knn label")

"""### **TSNE on testing data**"""

tsne13 = TSNE(n_components=2,random_state=0)
z13 = tsne13.fit_transform(x_test_r_knn)

df13 = pd.DataFrame()
df13["y_lr"] = y_pred_lr_r
df13["y_knn"] =y_pred_knn_r
df13["y_actual"] = y_test
df13["comp-1"] = z13[:,0]
df13["comp-2"] = z13[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df13.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df13).set(title="tsne on test with wraper RE filter data actual label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df13.y_lr.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df13).set(title="tsne on test with wraper RE filter data predicted lr label")

sns.scatterplot(x="comp-1", y="comp-2", hue=df13.y_knn.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df13).set(title="tsne on test with wraper RE filter data predicted knn label")

"""# **Question 5:Choose the best number of cluster for k-means clustering algorithm on the processed data**"""

x_train_b_knn

wcss=[]
scores =[]
for i in range(2,7):
  kmean = KMeans(n_clusters=i)
  y_pred = kmean.fit_predict(x_train_b_knn)
  wcss.append(kmean.inertia_)
  scores.append(silhouette_score(x_train_b_knn,y_pred))


plt.plot(range(2,7),scores)
plt.title('k value vs silhouette score')
plt.xlabel('k value')
plt.ylabel('silhouette score')

plt.plot(range(2,7),wcss)
plt.title('k value vs wcss')
plt.xlabel('k value')
plt.ylabel('wcss')

visualizer = KElbowVisualizer(kmean, k=(2,7))
visualizer.fit(x_train_b_knn)       
visualizer.show()

# decide to choose K =2 because we have the highest silhouette score
kmean =KMeans(n_clusters=2)
kmean.fit(x_train_b_knn)
y_pred_train = kmean.predict(x_train_b_knn)
y_pred_test = kmean.predict(x_test_b_knn)

y_pred_test

y_pred_train

"""### **TSNE on training data**"""

tsne14 = TSNE(n_components=2,random_state=0)
z14 = tsne14.fit_transform(x_train_b_knn)

df14 = pd.DataFrame()
df14["y_actual"] = y_pred_train
df14["comp-1"] = z14[:,0]
df14["comp-2"] = z14[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df14.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df14).set(title="tsne on the best number of clusters on x_train")

"""### **TSNE on testing data**"""

tsne15 = TSNE(n_components=2,random_state=0)
z15 = tsne15.fit_transform(x_test_b_knn)

df15 = pd.DataFrame()
df15["y_actual"] = y_pred_test
df15["comp-1"] = z15[:,0]
df15["comp-2"] = z15[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df15.y_actual.tolist(),
                palette=sns.color_palette("hls", 2),
                data=df15).set(title="tsne on the best number of clusters on x_test")

"""# **Qustion 6: Choose the best number of neurons for SOM algorithm, using the best features**

An SOM is mainly used for data visualization and provides a quick visual summary of the training instances. In a 2D rectangular grid, each cell is represented by a weight vector. For a trained SOM, each cell weight represents a summary of a few training examples. Cells in the close vicinity of each other have similar weights, and like examples can be mapped to cells in a small neighborhood of each other.
"""

! pip install minisom

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
X = sc.fit_transform(x_train_b_knn)
from minisom import MiniSom 
scores = [] 
for i in range(2,31):
  som = MiniSom(i,i, 6, sigma=0.3, learning_rate=0.5) # initialization of ixi SOM
  som.random_weights_init(X)

# Training

  som.train_random(X, 5000)
  # Weights are:
  wts = som.get_weights
  
# Returns the distance map from the weights:
  som.distance_map()
  from pylab import plot, axis, show, pcolor, colorbar, bone
  bone()
  pcolor(som.distance_map().T)       # Distance map as background
  colorbar()
  show()
  bone()

  pcolor(som.distance_map().T)

  colorbar() #gives legend

  markers = ['o', 's']                     # if the observation is fraud then red circular color or else green square

  colors = ['r', 'g']

  for i, x in enumerate(X):

      w = som.winner(x)

      plot(w[0] + 0.5,

          w[1] + 0.5,

          markers[y[i]],

          markeredgecolor = colors[y[i]],

          markerfacecolor = 'None',

          markersize = 10,

          markeredgewidth = 2)

  show()
  mappings = som.win_map(X)
  w = np.array([som.winner(x) for x in X]).T
  index = np.ravel_multi_index(w,(i,i))

  scores.append(silhouette_score(X,index))

x_train_b_knn

# the best number of neuron is 2 based on the highest silhouette score
plt.plot(range(2,31),scores)
plt.xlabel('number of neurons')
plt.ylabel('silhouette score')
plt.title('number of neuros vs silhouette score')

pca1 = PCA(n_components=2)
pca1 = pca1.fit_transform(x_train_b_knn)

som = MiniSom(2,1, 6, sigma=0.3, learning_rate=0.5,random_seed=0) # initialization of 2*1 SOM
intial_weight = som.get_weights().copy()
som.train_batch(np.array(x_train_b_knn), 1000) # trains the SOM with 1000 iterations
final_weight = som.get_weights()
w = np.array([som.winner(x) for x in np.array(x_train_b_knn)]).T
index = np.ravel_multi_index(w,(2,1))

index

intial_weight

final_weight

"""### **TSNE plot for all data with two components for the neuron**"""

tsne20 = TSNE(n_components=2,random_state=0)
z20 = tsne20.fit_transform(np.append(X,intial_weight.reshape(2,6),axis=0))

init_weight_x =  z20[-2:]

data = z20[:-2]

plt.title('intial weight ')
sns.scatterplot(data[:,0],data[:,1],hue = index)
sns.scatterplot(init_weight_x[:,0],init_weight_x[:,1],s=200,color = 'r')
plt.xlabel('tsn component1')
plt.xlabel('tsn component1')

"""### **TSNE plot for all data with two components for the neuron with PCA**"""

tsne21 = TSNE(n_components=2,random_state=0)
z21 = tsne21.fit_transform(np.append(X,final_weight.reshape(2,6),axis=0))

final_weight_x =  z21[-2:]

data1 = z21[:-2]

plt.title('final weight ')
sns.scatterplot(data[:,0],data[:,1],hue = index)
sns.scatterplot(final_weight_x[:,0],final_weight_x[:,1],s=200,color = 'r')
plt.xlabel('tsn component1')
plt.ylabel('tsn component2')

som = MiniSom(2,1, 2, sigma=0.3, learning_rate=0.5,random_seed=0) # initialization of 2*1 SOM
intial_weight = som.get_weights().copy()
som.train_batch(pca1, 1000) # trains the SOM with 1000 iterations
final_weight = som.get_weights()
w = np.array([som.winner(x) for x in pca1]).T
index = np.ravel_multi_index(w,(2,1))

intial_weight

intial_weight[1]

plt.title('intial weight ')
sns.scatterplot(pca1[:,0],pca1[:,1],hue = index)
sns.scatterplot([intial_weight[0][0][0]],[intial_weight[0][0][1]],s=200,color = 'r')
sns.scatterplot([intial_weight[1][0][0]],[intial_weight[1][0][1]],s=200,color = 'r')
sns.lineplot(intial_weight[:,:,0].flatten(),intial_weight[:,:,1].flatten(),color = 'r')
plt.xlabel('tsn component1')
plt.xlabel('tsn component1')

final_weight[:,:,1].flatten()

plt.title('final weight')
sns.scatterplot(pca1[:,0],pca1[:,1],hue = index)
sns.scatterplot([final_weight[0][0][0]],[final_weight[0][0][1]],s=200,color = 'r')
sns.scatterplot([final_weight[1][0][0]],[final_weight[1][0][1]],s=200,color = 'r')
sns.lineplot(final_weight[:,:,0].flatten(),final_weight[:,:,1].flatten(),color = 'r')
plt.xlabel('tsn component1')
plt.xlabel('tsn component1')

"""# **Question 7: Tune the epsilon (0.3-0.7) and minpoints (2-15) values to obtain the same number of clusters in Q6 by using DBSCAN**

The DBSCAN algorithm is based on this intuitive notion of “clusters” and “noise”. The key idea is that for each point of a cluster, the neighborhood of a given radius has to contain at least a minimum number of points.
"""

from sklearn.cluster import DBSCAN
scores_d=[]
n_cluster = []
out = []
eps = []
cluster =[]
epsilon = []
min_sample = []

for i in [0.3,0.32,0.35,0.38,0.4,0.5,0.6,0.7]:
  for j in range(2,16):

    clustering = DBSCAN(eps=i, min_samples=j).fit(x_train)
    print(np.unique(clustering.labels_))
    if len(np.unique(clustering.labels_))>1:
      scores_d.append(silhouette_score(x_train,clustering.labels_))
      min_sample.append(j)
      n_cluster.append(len(np.unique(clustering.labels_))-1)
      print(np.unique(clustering.labels_))
      epsilon.append(i)
      print('epsilon= ',i,'minpoint= ',j,'silhouette = ',silhouette_score(X,clustering.labels_),'number of cluster = ',len(np.unique(clustering.labels_)))
      
    print('epsilon= ',i,'minpoint= ',j,'number of cluster = ',len(np.unique(clustering.labels_)))
    out.append((j,len(np.unique(clustering.labels_))))
    eps.append((j,len(np.unique(clustering.labels_))))

df_1 = pd.DataFrame({'eps':epsilon,'minsample':min_sample,'silhouette':scores_d,'cluster':n_cluster})

top_10 = df_1[df_1['cluster']==2].nlargest(10,'silhouette')

top_10

plt.plot(range(1,11),top_10['cluster'],'bx-')
plt.scatter(range(1,11),top_10['cluster'],marker='x',c='r')
plt.xticks(range(1,11),top_10['eps'])

plt.xlabel('epsilon value of top 10')
plt.ylabel('n_cluster')
plt.title('epsilon vs n_cluster of top 10')
plt.show()

plt.plot(range(1,11),top_10['cluster'],'bx-')
plt.scatter(range(1,11),top_10['cluster'],marker='x',c='r')
plt.xticks(range(1,11),top_10['minsample'])
plt.xlabel('minsample value of top 10')
plt.ylabel('n_cluster')
plt.title('min_sample vs n_cluster of top 10')

x = []
y = []
for i in eps:
  x.append(i[0])
  y.append(i[1])
plt.plot(x,y)
plt.xlabel('epsilon value')
plt.ylabel('n_cluster')
plt.title('epsilon vs n_cluster')

x = []
y = []
for i in out:
  x.append(i[0])
  y.append(i[1])
plt.scatter(x,y)

plt.xlabel('minsampls')
plt.ylabel('n_cluster')
plt.title('minsamples vs n_cluster')

# the best epsilon and min samples is 0.5 as epsilon and samples[2:15] this values achieve the high siluoette score on the best feature

scores_d=[]
n_cluster = []
out = []
ep = []
for i in [0.3,0.4,0.5,0.6,0.7]:
  for j in range(2,16):
    clustering = DBSCAN(eps=i, min_samples=j).fit(x_train)
    if len(np.unique(clustering.labels_))>1:
      scores_d.append(silhouette_score(X,clustering.labels_))
      print('epsilon= ',i,'minpoint= ',j,'silhouette = ',silhouette_score(X,clustering.labels_),'number of cluster = ',len(np.unique(clustering.labels_)))
    n_cluster.append(len(np.unique(clustering.labels_)))
    print('epsilon= ',i,'minpoint= ',j,'number of cluster = ',len(np.unique(clustering.labels_)))
    out.append((j,len(np.unique(clustering.labels_))))
    ep.append((i,len(np.unique(clustering.labels_))))

# the best epsilon and min samples is 0.5 as epsilon and samples[2:15] this values achieve the high siluoette score on the best feature

x = []
y = []
for i in ep:
  x.append(i[0])
  y.append(i[1])
plt.plot(x,y)
plt.xlabel('epsilon value')
plt.ylabel('n_cluster')
plt.title('epsilon vs n_cluster')

x = []
y = []
for i in out:
  x.append(i[0])
  y.append(i[1])
plt.scatter(x,y)

plt.xlabel('minsampls')
plt.ylabel('n_cluster')
plt.title('minsamples vs n_cluster')
plt.legend(labels=['it dependance the epsilon value'])